network: "transformer_simple"
#-----Organize train, test, validation
train_batch_size: 8


valid_batch_size: 1

test_batch_size: 1

learning_rate: 0.00005

reload_model:
  type: False
  data: "1_fev"

model:
  TimeSeriesTransformers:
    n_encoder_layers: 3
    n_decoder_layers: 3

optimizer:
  Adam:
    lr: 0.0001
    weight_decay: 0.01

loss:
  MSELoss: MSEloss
  # KullbackLeibler: KullbackLeibler

epochs: 20


#----- Train test split
train_test_split:
  test_size: 0.15
  random_state: 42

#--- path save model
path_save_model: 'models_h5/'
name_model: 'model_batch_4.h5'

#evaluate step mafalda biggest dataset
evaluate_step: 20000

schedule: 100

#----- wandb
wandb: False

#---- DIR dataset mafaulda
train_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_dataset/train_compressor_data.h5'
    context: 400
    stride: 1

valid_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_dataset/test_compressor_data.h5'
    context: 400
    stride: 1

test_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_dataset/9100_points/test_compressor_data.h5'
    context: 400
    stride: 1

path_to_save_model: 'model_h5/'
