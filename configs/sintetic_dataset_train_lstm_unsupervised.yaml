network: "LSTM_decoder_sintetic"
#-----Organize train, test, validation
train:
  batch_size: 8

valid:
  batch_size: 1

test:
  batch_size: 50

learning_rate: 0.00005

reload_model:
  type: True
  data: "23_jan"

model:
  LstmModel:
    input_dim: 400
    hidden_dim: 20
    num_layers: 2
    output_dim: 1

optimizer:
  Adam:
    lr: 0.0001
    weight_decay: 0.01

loss:
  MSELoss: MSEloss

epochs: 1


#----- Train test split
train_test_split:
  test_size: 0.15
  random_state: 42

#--- path save model
path_save_model: 'models_h5/'
name_model: 'model_batch_4.h5'

#evaluate step mafalda biggest dataset
evaluate_step: 20000

schedule: 10000

#----- wandb
wandb: False

#---- DIR dataset mafaulda
train_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_data/train_compressor_data.h5'
    context: 400
    stride: 1

valid_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_data/train_compressor_data.h5'
    context: 400
    stride: 1

test_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_data/test_compressor_data.h5'
    context: 400
    stride: 400

path_to_save_model: 'model_h5/'
