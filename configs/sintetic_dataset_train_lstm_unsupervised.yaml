network: "just_LSTM_sintetic"
#-----Organize train, test, validation
train_batch_size: 16

valid_batch_size: 1

test_batch_size: 50

learning_rate: 0.00005

reload_model:
  type: True
  data: "25_jan"

model:
  LstmModel:
    num_sensors: 1 #input_dim
    hidden_units: 512
    num_layers: 15
    output_dim: 1

optimizer:
  Adam:
    lr: 0.0001
    weight_decay: 0.01

loss:
  MSELoss: MSEloss

epochs: 20


#----- Train test split
train_test_split:
  test_size: 0.15
  random_state: 42

#--- path save model
path_save_model: 'models_h5/'
name_model: 'model_batch_4.h5'

#evaluate step mafalda biggest dataset
evaluate_step: 20000

schedule: 10000

#----- wandb
wandb: True

#---- DIR dataset mafaulda
train_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_data/train_compressor_data.h5'
    context: 400
    stride: 1

valid_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_data/train_compressor_data.h5'
    context: 400
    stride: 1

test_dataset:
  DatasetSinteticUnsupervisedLSTM:
    dir_data: 'Datasets/sintetic_data/test_compressor_data.h5'
    context: 400
    stride: 400

path_to_save_model: 'model_h5/'
