# -*- coding: utf-8 -*-
"""Autoencoder_data_stdandmean.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GH8isoFn_fyG2NoJf0-IzASYQFD9G1e2
"""

import numpy as np
import random
import matplotlib.pyplot as plt
from sklearn import preprocessing

"""Bomba"""

frequency = 65 #Hz
time = 10 #sec
slot = 100000000


data = np.ones((slot, time, frequency, 4))
for i in range(len(data)):
  for j in range(len(data[i])):
    data[i][j] = np.transpose(np.array([np.random.normal(random.choice([1020. , 1020.5, 1021. , 1021.5, 1022. , 1022.5, 1023. , 1023.5,
       1024. , 1024.5, 1025. , 1025.5, 1026. , 1026.5, 1027. , 1027.5,
       1028. , 1028.5, 1029. , 1029.5]), 18, frequency),  #1026.84
                                        np.random.normal(random.choice([20. , 20.5, 21. , 21.5, 22. , 22.5, 23. , 23.5, 24. , 24.5, 25. ,
       25.5, 26. , 26.5, 27. , 27.5, 28. , 28.5, 29. , 29.5]), 12, frequency), #26.52
                                        np.random.normal(random.choice([80. , 80.5, 81. , 81.5, 82. , 82.5, 83. , 83.5, 84. , 84.5, 85. ,
       85.5, 86. , 86.5, 87. , 87.5, 88. , 88.5, 89. , 89.5]), 5, frequency), #84.58
                                        np.random.normal(random.choice([95. ,  95.5,  96. ,  96.5,  97. ,  97.5,  98. ,  98.5,  99. ,
        99.5, 100. , 100.5, 101. , 101.5, 102. , 102.5, 103. , 103.5,
       104. , 104.5]), 5, frequency)])) #100

for i in range(len(data)):
  for j in range(len(data[i])):
    data[i][j] = preprocessing.normalize(data[i][j])

print(data.shape)

plt.plot(data[0,0,:,0]) #out_pressure
plt.show()

plt.plot(data[0,0,:,1]) #in_pressure
plt.show()

plt.plot(data[0,0,:,2]) #temperature
plt.show()

plt.plot(data[0,0,:,3]) #speed limit
plt.show()

from sklearn.model_selection import train_test_split

X_train, X_test = train_test_split(data, test_size=0.15, random_state=1)

print(X_train.shape)
print(X_test.shape)

"""Custom Generator"""

BATCH_SIZE = 4096
IMAGE_SHAPE = (10,65)
INPUT_SHAPE = IMAGE_SHAPE + (4,)

import tensorflow as tf
class CustomGen(tf.keras.utils.Sequence):
    def __init__(self, 
                 x,
                 batch_size,
                 image_shape,
                 shuffle=True):
        self.image_shape =image_shape
        self.x = x
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.__shuffle_data__()
        self.n = (np.ceil(len(self.x) / float(self.batch_size))).astype(np.int)
    
    def __getitem__(self, index):
        batch_video = self.x[index * self.batch_size : (index+1) * self.batch_size]
        batch_video = np.array(batch_video)
        return batch_video,batch_video
    
    def __len__(self):
        return self.n 
        
    def __shuffle_data__(self):
        random.shuffle(self.x)
        
    def on_epoch_end(self):
        if self.shuffle:
            self.__shuffle_data__()

import gc
train_gen = CustomGen(X_train, batch_size = BATCH_SIZE,image_shape = INPUT_SHAPE, shuffle=True)
test_gen = CustomGen(X_test, batch_size = BATCH_SIZE,image_shape = INPUT_SHAPE, shuffle=True)
print(len(train_gen.x))
del X_train
del X_test

"""*AutoEncoder*"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Dense, Dropout, add, UpSampling2D, Flatten, Lambda, Input, BatchNormalization, ReLU, AveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import Model

mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():

    input_img = Input(shape=INPUT_SHAPE)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 1), padding='same')(x)
    x = Conv2D(16, (3, 2), activation='relu', padding='same')(x)
    encoded = MaxPooling2D((2, 2), padding='same')(x)

    x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
    x = UpSampling2D((2, 2))(x)
    print('1:', x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    print('2:', x)
    x = Conv2D(64,(4, 4), activation='relu')(x)
    x = UpSampling2D((2, 1))(x)
    print('3:', x)
    decoded = Conv2D(4, (3, 3), activation='sigmoid', padding='same')(x)
    print('4:', decoded)
    autoencoder = Model(input_img, decoded)
    autoencoder.compile(optimizer=Adam(lr=0.00001), loss='BinaryCrossentropy')
    
    autoencoder.summary()

autoencoder.fit(train_gen,
                epochs=100,
                validation_data=test_gen)

autoencoder.save('autoencoder_model_std_fix_mean_variational.h5')