# -*- coding: utf-8 -*-
"""Autoencoder_data_stdandmean_fix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GH8isoFn_fyG2NoJf0-IzASYQFD9G1e2
"""

import numpy as np
import random
import matplotlib.pyplot as plt
from sklearn import preprocessing

"""Bomba"""

frequency = 65 #Hz
time = 10 #sec
slot = 100000000


data = np.ones((slot, time, frequency, 4))
for i in range(len(data)):
  for j in range(len(data[i])):
    data[i][j] = np.transpose(np.array([np.random.normal(1026.84, random.choice([16, 17, 18, 19, 20]), frequency), 
                                        np.random.normal(26.52, random.choice([10, 11, 12, 13, 14]), frequency),
                                        np.random.normal(84.58, random.choice([3, 4, 5, 6, 7]), frequency),
                                        np.random.normal(100, random.choice([3, 4, 5, 6, 7]), frequency)]))

for i in range(len(data)):
  for j in range(len(data[i])):
    data[i][j] = preprocessing.normalize(data[i][j])

print(data.shape)

plt.plot(data[0,0,:,0]) #out_pressure
plt.show()

plt.plot(data[0,0,:,1]) #in_pressure
plt.show()

plt.plot(data[0,0,:,2]) #temperature
plt.show()

plt.plot(data[0,0,:,3]) #speed limit
plt.show()

import h5py
h5f = h5py.File('compressor_data.h5', 'w')
h5f.create_dataset('Data', data = data)

from sklearn.model_selection import train_test_split

X_train, X_test = train_test_split(data, test_size=0.15, random_state=1)

print(X_train.shape)
print(X_test.shape)

"""Custom Generator"""

BATCH_SIZE = 4096
IMAGE_SHAPE = (10,65)
INPUT_SHAPE = IMAGE_SHAPE + (4,)

import tensorflow as tf
class CustomGen(tf.keras.utils.Sequence):
    def __init__(self, 
                 x,
                 batch_size,
                 image_shape,
                 shuffle=True):
        self.image_shape =image_shape
        self.x = x
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.__shuffle_data__()
        self.n = (np.ceil(len(self.x) / float(self.batch_size))).astype(np.int)
    
    def __getitem__(self, index):
        batch_video = self.x[index * self.batch_size : (index+1) * self.batch_size]
        batch_video = np.array(batch_video)
        return batch_video,batch_video
    
    def __len__(self):
        return self.n 
        
    def __shuffle_data__(self):
        random.shuffle(self.x)
        
    def on_epoch_end(self):
        if self.shuffle:
            self.__shuffle_data__()

import gc
train_gen = CustomGen(X_train, batch_size = BATCH_SIZE,image_shape = INPUT_SHAPE, shuffle=True)
test_gen = CustomGen(X_test, batch_size = BATCH_SIZE,image_shape = INPUT_SHAPE, shuffle=True)
print(len(train_gen.x))
del X_train
del X_test

"""*AutoEncoder*"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Dense, Dropout, add, UpSampling2D, Flatten, Lambda, Input, BatchNormalization, ReLU, AveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import Model

mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():

    input_img = Input(shape=INPUT_SHAPE)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 1), padding='same')(x)
    x = Conv2D(16, (3, 2), activation='relu', padding='same')(x)
    encoded = MaxPooling2D((2, 2), padding='same')(x)

    x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
    x = UpSampling2D((2, 2))(x)
    print('1:', x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    print('2:', x)
    x = Conv2D(64,(4, 4), activation='relu')(x)
    x = UpSampling2D((2, 1))(x)
    print('3:', x)
    decoded = Conv2D(4, (3, 3), activation='sigmoid', padding='same')(x)
    print('4:', decoded)
    autoencoder = Model(input_img, decoded)
    autoencoder.compile(optimizer=Adam(lr=0.00001), loss='BinaryCrossentropy')
    
    autoencoder.summary()

autoencoder.fit(train_gen,
                epochs=100,
                validation_data=test_gen)

autoencoder.save('autoencoder_model_std_variational_mean_fix.h5')