{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9s2HYL8wNDn",
        "outputId": "a31f19c0-675b-4a80-dbf0-8b77fc1183c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34, 249999, 8, 1) (35, 249999, 8, 1)\n",
            "(7, 249999, 8, 1) (8, 249999, 8, 1)\n",
            "(8, 249999, 8, 1) (8, 249999, 8, 1)\n",
            "(49, 1, 249999, 8)\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7fc8fdd6e410>\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "path_train_normal = '/content/drive/MyDrive/Wile_C/Dataset_normal_vertical0.51/X_train_normal.h5'\n",
        "path_train_failure = '/content/drive/MyDrive/Wile_C/Dataset_normal_vertical0.51/X_train_failure.h5'\n",
        "X_train_normal = h5py.File(path_train_normal, 'r+')\n",
        "X_train_failure = h5py.File(path_train_failure, 'r+')\n",
        "X_train_normal = np.array(X_train_normal['X_train'])\n",
        "X_train_failure = np.array(X_train_failure['X_train'])\n",
        "print(X_train_normal.shape, X_train_failure.shape)\n",
        "\n",
        "path_test_normal = '/content/drive/MyDrive/Wile_C/Dataset_normal_vertical0.51/X_test_normal.h5'\n",
        "path_test_failure = '/content/drive/MyDrive/Wile_C/Dataset_normal_vertical0.51/X_test_failure.h5'\n",
        "X_test_normal = h5py.File(path_test_normal, 'r+')\n",
        "X_test_failure = h5py.File(path_test_failure, 'r+')\n",
        "X_test_normal = np.array(X_test_normal['X_test'])\n",
        "X_test_failure = np.array(X_test_failure['X_test'])\n",
        "print(X_test_normal.shape, X_test_failure.shape)\n",
        "\n",
        "path_val_normal = '/content/drive/MyDrive/Wile_C/Dataset_normal_vertical0.51/X_val_normal.h5'\n",
        "path_val_failure = '/content/drive/MyDrive/Wile_C/Dataset_normal_vertical0.51/X_val_failure.h5'\n",
        "X_val_normal = h5py.File(path_val_normal, 'r+')\n",
        "X_val_failure = h5py.File(path_val_failure, 'r+')\n",
        "X_val_normal = np.array(X_val_normal['X_val'])\n",
        "X_val_failure = np.array(X_val_failure['X_val'])\n",
        "print(X_val_normal.shape, X_val_failure.shape)\n",
        "\n",
        "X_train = np.reshape(X_train_normal, (34,1,249999,8))\n",
        "X_val = np.reshape(X_val_normal, (8,1,249999,8))\n",
        "X_test = np.reshape(X_test_normal, (7,1,249999,8))\n",
        "X_train = np.concatenate((X_train, X_val, X_test), axis=0)\n",
        "print(X_train.shape)\n",
        "y_train = np.ones(len(X_train))\n",
        "\n",
        "data = TensorDataset(torch.as_tensor(X_train).float(), torch.as_tensor(y_train))\n",
        "data = DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "    base_out = self.base_model(x)\n",
        "        \n",
        "    self.mu = self.lin_mu(base_out)\n",
        "    self.log_var = self.lin_var(base_out)\n",
        "    std = torch.exp(self.log_var/2)\n",
        "                \n",
        "    eps = torch.randn_like(self.mu)\n",
        "    z = self.mu + eps * std\n",
        "    return z"
      ],
      "metadata": {
        "id": "HztcIfjowkJB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.enc = encoder\n",
        "        self.dec = decoder\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # when encoder met decoder\n",
        "        enc_out = self.enc(x)\n",
        "        return self.dec(enc_out)"
      ],
      "metadata": {
        "id": "Lz9h4uqBwpst"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_div(mu, std):\n",
        "    kl_div = -0.5*(1 + np.log(std**2) - mu**2 - std**2)\n",
        "    return kl_div"
      ],
      "metadata": {
        "id": "mN14To8-ws0E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(self, seed=42):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "class EncoderVar(nn.Module):\n",
        "    def __init__(self, input_shape, z_size, base_model):\n",
        "        super().__init__()\n",
        "        self.z_size = z_size\n",
        "        self.input_shape = input_shape\n",
        "        self.base_model = base_model\n",
        "        output_size = self.get_output_size()\n",
        "        self.lin_mu = nn.Linear(output_size, z_size)\n",
        "        self.lin_var = nn.Linear(output_size, z_size)\n",
        "        \n",
        "    def get_output_size(self):\n",
        "        device = next(self.base_model.parameters()).device.type\n",
        "        size = self.base_model(torch.zeros(1, *self.input_shape, device=device)).size(1)\n",
        "        return size\n",
        "    \n",
        "    def kl_loss(self):\n",
        "        kl_loss = -0.5*(1 + self.log_var - self.mu**2 - torch.exp(self.log_var))\n",
        "        return kl_loss\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # the base model, same as the traditional AE\n",
        "        base_out = self.base_model(x)\n",
        "        \n",
        "        # now the encoder produces means (mu) using the lin_mu output layer\n",
        "        # and log variances (log_var) using the lin_var output layer\n",
        "        # we compute the standard deviation (std) from the log variance\n",
        "        self.mu = self.lin_mu(base_out)\n",
        "        self.log_var = self.lin_var(base_out)\n",
        "        std = torch.exp(self.log_var/2)\n",
        "                \n",
        "        # that's the internal random input (epsilon)\n",
        "        eps = torch.randn_like(self.mu)\n",
        "        # and that's the z vector\n",
        "        z = self.mu + eps * std\n",
        "        \n",
        "        return z"
      ],
      "metadata": {
        "id": "eQAqQ-sBxSTJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(13)\n",
        "\n",
        "z_size = 1\n",
        "n_filters = 16\n",
        "in_channels = 1\n",
        "img_size_H = 249999\n",
        "img_size_W = 8\n",
        "input_shape = (in_channels, img_size_H, img_size_W)\n",
        "\n",
        "base_model = nn.Sequential(\n",
        "    # in_channels@28x28 -> n_filters@28x28\n",
        "    nn.Conv2d(in_channels, n_filters, kernel_size=3, stride=1, padding=1),\n",
        "    nn.LeakyReLU(),\n",
        "            \n",
        "    # n_filters@28x28 -> (n_filters*2)@14x14\n",
        "    nn.Conv2d(n_filters, n_filters*2, kernel_size=3, stride=2, padding=1),\n",
        "    nn.LeakyReLU(),\n",
        "    \n",
        "    # (n_filters*2)@14x14 -> (n_filters*2)@7x7\n",
        "    nn.Conv2d(n_filters*2, n_filters*2, kernel_size=3, stride=2, padding=1),\n",
        "    nn.LeakyReLU(),\n",
        "    \n",
        "    # (n_filters*2)@7x7 -> (n_filters*2)@7x7\n",
        "    nn.Conv2d(n_filters*2, n_filters*2, kernel_size=3, stride=1, padding=1),\n",
        "    nn.LeakyReLU(),\n",
        "    \n",
        "    # (n_filters*2)@7x7 -> (n_filters*2)*7*7\n",
        "    nn.Flatten(),\n",
        ")\n",
        "\n",
        "encoder_var_cnn = EncoderVar(input_shape, z_size, base_model)\n",
        "\n",
        "decoder_cnn = nn.Sequential(\n",
        "    # z_size -> (n_filters*2)*7*7\n",
        "    nn.Linear(z_size, (n_filters*2)*int(img_size_H/4)*int(img_size_W/4)),\n",
        "    \n",
        "    # (n_filters*2)*7*7 -> (n_filters*2)@7x7\n",
        "    nn.Unflatten(1, (n_filters*2, int(img_size_H/4), int(img_size_W/4))),\n",
        "    \n",
        "    # (n_filters*2)@7x7 -> (n_filters*2)@7x7\n",
        "    nn.ConvTranspose2d(n_filters*2, n_filters*2, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
        "    nn.LeakyReLU(),\n",
        "\n",
        "    # (n_filters*2)@7x7 -> (n_filters*2)@14x14\n",
        "    nn.ConvTranspose2d(n_filters*2, n_filters*2, kernel_size=(4,3), stride=2, padding=1, output_padding=1),\n",
        "    nn.LeakyReLU(),\n",
        "    \n",
        "    # (n_filters*2)@15x15 -> n_filters@28x28\n",
        "    nn.ConvTranspose2d(n_filters*2, n_filters, kernel_size=(4,3), stride=2, padding=1, output_padding=1),\n",
        "    nn.LeakyReLU(),\n",
        "    \n",
        "    # n_filters@28x28 -> in_channels@28x28\n",
        "    nn.ConvTranspose2d(n_filters, in_channels, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
        "    nn.Sigmoid(),\n",
        ")"
      ],
      "metadata": {
        "id": "UEeaZZIRxWOh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_var_cnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5HD010pxZZ6",
        "outputId": "a6074520-85ea-4d86-beb5-7b13459d42e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderVar(\n",
              "  (base_model): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (3): LeakyReLU(negative_slope=0.01)\n",
              "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (5): LeakyReLU(negative_slope=0.01)\n",
              "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): LeakyReLU(negative_slope=0.01)\n",
              "    (8): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (lin_mu): Linear(in_features=4000000, out_features=1, bias=True)\n",
              "  (lin_var): Linear(in_features=4000000, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_cnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peIo3oq2xb5N",
        "outputId": "90195363-18f5-41d0-fcb4-082926a6f2ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=3999936, bias=True)\n",
              "  (1): Unflatten(dim=1, unflattened_size=(32, 62499, 2))\n",
              "  (2): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): LeakyReLU(negative_slope=0.01)\n",
              "  (4): ConvTranspose2d(32, 32, kernel_size=(4, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (5): LeakyReLU(negative_slope=0.01)\n",
              "  (6): ConvTranspose2d(32, 16, kernel_size=(4, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (7): LeakyReLU(negative_slope=0.01)\n",
              "  (8): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (9): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_vae_cnn = AutoEncoder(encoder_var_cnn, decoder_cnn)\n",
        "model_vae_cnn.to(device)\n",
        "loss_fn = nn.MSELoss(reduction='none')\n",
        "optim = torch.optim.Adam(model_vae_cnn.parameters(), 0.0003)\n",
        "\n",
        "num_epochs = 200\n",
        "\n",
        "train_losses = []\n",
        "\n",
        "reconstruction_loss_factor = 1\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    batch_losses = []\n",
        "    for i, (x, _) in enumerate(data):\n",
        "        model_vae_cnn.train()\n",
        "        x = x.to(device)\n",
        "        #print(x.shape)\n",
        "\n",
        "        # Step 1 - Computes our model's predicted output - forward pass\n",
        "        yhat = model_vae_cnn(x)\n",
        "        #print(yhat.shape)\n",
        "\n",
        "        # Step 2 - Computes the loss\n",
        "        loss = loss_fn(yhat, x).sum(dim=[1, 2, 3]).sum(dim=0)\n",
        "        kl_loss = model_vae_cnn.enc.kl_loss().sum(dim=1).sum(dim=0)\n",
        "        total_loss = reconstruction_loss_factor * loss + kl_loss\n",
        "\n",
        "        # Step 3 - Computes gradients\n",
        "        total_loss.backward()\n",
        "\n",
        "        # Step 4 - Updates parameters using gradients and the learning rate\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        \n",
        "        batch_losses.append(np.array([total_loss.data.item(), loss.data.item(), kl_loss.data.item()]))\n",
        "\n",
        "    # Average over batches\n",
        "    train_losses.append(np.array(batch_losses).mean(axis=0))\n",
        "\n",
        "    print(f'Epoch {epoch:03d} | Loss >> {train_losses[-1][0]:.4f}/{train_losses[-1][1]:.4f}/{train_losses[-1][2]:.4f}')"
      ],
      "metadata": {
        "id": "kj2umsWJxdxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}