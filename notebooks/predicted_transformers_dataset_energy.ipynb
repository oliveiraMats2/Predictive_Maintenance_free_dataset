{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f45a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2edc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
      "2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "                     MT_008  MT_009  MT_010  ...  MT_361  MT_362  MT_363  \\\n",
      "2011-01-01 00:15:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "2011-01-01 00:30:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "2011-01-01 00:45:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "2011-01-01 01:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "2011-01-01 01:15:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "\n",
      "                     MT_364  MT_365  MT_366  MT_367  MT_368  MT_369  MT_370  \n",
      "2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 370 columns]\n"
     ]
    }
   ],
   "source": [
    "dir_dataset = '../Datasets/dataset_fusion_transfomers/LD2011_2014.txt'\n",
    "data = pd.read_csv(dir_dataset, index_col=0, sep=';', decimal=',')\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "print(data.head(5))\n",
    "\n",
    "# down sampling of the information\n",
    "data = data.resample('1h').mean().replace(0., np.nan)\n",
    "earliest_time = data.index.min()\n",
    "#df = data[['MT_002', 'MT_004', 'MT_005', 'MT_006', 'MT_008']]\n",
    "df = data[['MT_004']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df59b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in df:\n",
    "    ts = df[label]\n",
    "\n",
    "    start_date = min(ts.fillna(method='ffill').dropna().index)\n",
    "    end_date = max(ts.fillna(method='bfill').dropna().index)\n",
    "\n",
    "    active_range = (ts.index >= start_date) & (ts.index <= end_date)\n",
    "    ts = ts[active_range].fillna(0.)\n",
    "\n",
    "    tmp = pd.DataFrame({'power_usage': ts})\n",
    "    date = tmp.index\n",
    "\n",
    "    tmp['hours_from_start'] = (date - earliest_time).seconds / 60 / 60 + (date - earliest_time).days * 24\n",
    "    tmp['hours_from_start'] = tmp['hours_from_start'].astype('int')\n",
    "\n",
    "    tmp['days_from_start'] = (date - earliest_time).days\n",
    "    tmp['date'] = date\n",
    "    tmp['consumer_id'] = label\n",
    "    tmp['hour'] = date.hour\n",
    "    tmp['day'] = date.day\n",
    "    tmp['day_of_week'] = date.dayofweek\n",
    "    tmp['month'] = date.month\n",
    "\n",
    "time_df = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06707e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 24\n",
    "max_encoder_length = 7 * 24\n",
    "training_cutoff = time_df[\"hours_from_start\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    time_df[lambda x: x.hours_from_start <= training_cutoff],\n",
    "    time_idx=\"hours_from_start\",\n",
    "    target=\"power_usage\",\n",
    "    group_ids=[\"consumer_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"consumer_id\"],\n",
    "    time_varying_known_reals=[\"hours_from_start\",'hour'],\n",
    "    time_varying_unknown_reals=['power_usage'],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"consumer_id\"], transformation=\"softplus\"\n",
    "    ),  # we normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, time_df, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for  our model\n",
    "batch_size = 64\n",
    "# if you have a strong GPU, feel free to increase the number of workers\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98e57e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paim/anaconda3/envs/ocr_estacio/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:268: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/home/paim/anaconda3/envs/ocr_estacio/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:268: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 716.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_cat': tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]]), 'x_cont': tensor([[ 1.0000e+00,  4.2633e-14,  1.4211e-14,  ..., -1.5167e+00,\n",
      "         -1.0000e+00,  8.7087e-01],\n",
      "        [ 1.0000e+00,  4.2633e-14,  1.4211e-14,  ..., -1.3723e+00,\n",
      "         -9.9405e-01,  1.5256e-01],\n",
      "        [ 1.0000e+00,  4.2633e-14,  1.4211e-14,  ..., -1.2278e+00,\n",
      "         -9.8810e-01, -7.0639e-03],\n",
      "        ...,\n",
      "        [ 1.0000e+00,  4.2633e-14,  1.4211e-14,  ...,  1.5169e+00,\n",
      "          1.2500e-01,  1.3497e+00],\n",
      "        [ 1.0000e+00,  4.2633e-14,  1.4211e-14,  ...,  1.6613e+00,\n",
      "          1.3095e-01,  1.3630e+00],\n",
      "        [ 1.0000e+00,  4.2633e-14,  1.4211e-14,  ..., -1.6612e+00,\n",
      "          1.3690e-01,  1.8153e+00]]), 'encoder_length': 168, 'decoder_length': 24, 'encoder_target': tensor([142.7845, 115.3455, 109.2480, 108.2317, 110.2642, 112.8049, 103.1504,\n",
      "        112.8049, 126.5244, 133.1301, 167.6829, 178.3537, 140.7520, 139.2276,\n",
      "        131.0976, 132.1138, 170.2236, 206.3008, 201.7276, 180.3862, 164.1260,\n",
      "        169.2073, 161.0772, 151.9309, 161.5854, 140.7520, 130.0813, 115.8537,\n",
      "        110.7724, 111.2805,  82.8252,  68.0894,  89.9390, 122.4594, 138.2114,\n",
      "        181.9106, 138.7195, 107.7236, 108.2317, 114.3293, 127.0325, 166.1585,\n",
      "        166.6667, 167.6829, 176.8293, 175.3049, 176.3211, 145.8333, 117.3781,\n",
      "        109.7561, 108.7398, 101.1179, 104.1667, 107.2154, 105.6911, 107.2154,\n",
      "        119.9187, 125.0000, 161.0772, 159.0447, 133.1301, 115.3455, 112.8049,\n",
      "        117.3781, 155.4878, 195.1219, 223.0691, 233.7398, 220.5285, 208.3333,\n",
      "        182.4187, 159.0447, 137.1951, 116.8699, 111.7886, 104.1667, 104.1667,\n",
      "        102.1341,  97.0528,  97.0528, 140.7520, 147.3577, 169.2073, 168.6992,\n",
      "        173.7805, 157.0122, 158.5366, 141.7683, 169.7155, 218.4959, 255.0813,\n",
      "        217.9878, 209.8577, 180.3862, 198.1707, 169.7155, 136.1789, 120.9350,\n",
      "        113.3130, 106.1992, 107.7236, 110.7724, 104.6748,  86.3821, 110.2642,\n",
      "        148.3740, 193.0894, 231.1992, 174.7968, 137.1951, 133.1301, 130.5894,\n",
      "        149.3902, 182.9268, 194.6138, 203.7602, 203.7602, 176.8293, 155.9959,\n",
      "        134.6545, 124.4919, 118.9024, 104.6748, 108.2317, 109.7561, 118.9024,\n",
      "        114.3293, 119.4106, 118.3943, 129.5732, 122.9675, 135.1626, 134.1463,\n",
      "        114.8374, 119.4106, 111.2805, 158.5366, 220.0203, 246.9512, 226.1179,\n",
      "        224.0854, 223.0691, 178.8618, 160.0610, 141.2602, 122.9675, 121.9512,\n",
      "        107.2154, 117.3781, 116.3618, 129.0650, 112.2967, 116.8699, 120.4268,\n",
      "        142.2764, 134.1463, 127.5406, 112.2967, 105.1829, 112.8049, 125.5081,\n",
      "        211.8902, 256.6057, 235.2642, 242.3781, 215.9553, 184.9594, 174.7968]), 'encoder_time_idx_start': tensor(34873), 'groups': tensor([0]), 'target_scale': array([109.51780364,  38.19942918])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for dimension 1 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_823929/1509949625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_tft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# average p50 loss overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ocr_estacio/lib/python3.9/site-packages/pytorch_forecasting/models/base_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, mode, return_index, return_decoder_lengths, batch_size, num_workers, fast_dev_run, show_progress_bar, return_x, mode_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# raw output is dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                 \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decoder_lengths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ocr_estacio/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ocr_estacio/lib/python3.9/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0minput_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         input_vectors.update(\n\u001b[0;32m--> 410\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_reals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ocr_estacio/lib/python3.9/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    409\u001b[0m         input_vectors.update(\n\u001b[1;32m    410\u001b[0m             {\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_reals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for dimension 1 with size 7"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir_model = \"/mnt/arquivos_linux/wile_C/Predictive_Maintenance_free_dataset/lightning_logs/version_0/checkpoints/epoch=6-step=2877.ckpt\"\n",
    "\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(dir_model)\n",
    "\n",
    "actuals = torch.cat([y[0] for x, y in tqdm(iter(val_dataloader))])\n",
    "print((val_dataloader.dataset[0][0]))\n",
    "\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "\n",
    "# average p50 loss overall\n",
    "print((actuals - predictions).abs().mean().item())\n",
    "# average p50 loss per time series\n",
    "print((actuals - predictions).abs().mean(axis=1))\n",
    "\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "print(raw_predictions._fields)\n",
    "\n",
    "print('\\n')\n",
    "print(raw_predictions['prediction'].shape)\n",
    "\n",
    "\n",
    "best_tft.plot_prediction(x, raw_predictions, idx=0, add_loss_to_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c43631",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(raw_predictions.prediction.shape[0]):\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8d3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
